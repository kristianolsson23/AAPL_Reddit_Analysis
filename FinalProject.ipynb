{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979923b5-0493-4768-ad1a-06db54f0bc7a",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "\n",
    "DS 5001 Exploratory Text Analytics | Spring 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046f57f-12ed-4259-be3d-60cb67b8d044",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "- Full Name: Kristian Olsson\n",
    "- Userid: kno5cac\n",
    "- GitHub Repo URL: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis\n",
    "- UVA Box URL: https://virginia.box.com/s/yhex3pa1hpcdn2x1dniu06lsxqkajlrh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acd11d-eb04-4bcc-b115-f205f367de49",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of the final project is for you to create a **digital analytical edition** of a corpus using the tools, practices, and perspectives youâ€™ve learning in this course. You will select a corpus that has already been digitized and transcribed, parse that into an F-compliant set of tables, and then generate and visualize the results of a series of fitted models. You will also draw some tentative conclusions regarding the linguistic, cultural, psychological, or historical features represented by your corpus. The point of the exercise is to have you work with a corpus through the entire pipeline from ingestion to interpretation. \n",
    "\n",
    "Specifically, you will acquire a collection of long-form texts and perform the following operations:\n",
    "\n",
    "- **Convert** the collection from their source formats (F0) into a set of tables that conform to the Standard Text Analytic Data Model (F2).\n",
    "- **Annotate** these tables with statistical and linguistic features using NLP libraries such as NLTK (F3).\n",
    "- **Produce** a vector representation of the corpus to generate TFIDF values to add to the TOKEN (aka CORPUS) and VOCAB tables (F4).\n",
    "- **Model** the annotated and vectorized model with tables and features derived from the application of unsupervised methods, including PCA, LDA, and word2vec (F5).\n",
    "- **Explore** your results using statistical and visual methods.\n",
    "- **Present** conclusions about patterns observed in the corpus by means of these operations.\n",
    "\n",
    "When you are finished, you will make the results of your work available in GitHub (for code) and UVA Box (for data). You will submit to Gradescope (via Canvas) a PDF version of a Jupyter notebook that contains the information listed below.\n",
    "\n",
    "# Some Details\n",
    "\n",
    "- Please fill out your answers in each task below by editing the markdown cell. \n",
    "- Replace text that asks you to insert something with the thing, i.e. replace `(INSERT IMAGE HERE)` with an image element, e.g. `![](image.png)`.\n",
    "- For URLs, just paste the raw URL directly into the text area. Don't worry about providing link labels using `[label](link)`.\n",
    "- Please do not alter the structure of the document or cell, i.e. the bulleted lists. \n",
    "- You may add explanatory paragraphs below the bulleted lists.\n",
    "- Please name your tables as they are named in each task below.\n",
    "- Tasks are indicated by headers with point values in parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b6d68-e039-4612-858b-29510eeb5365",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0889de-cd53-4aa5-80b2-a2a39060776a",
   "metadata": {},
   "source": [
    "## Source Description (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e395a-4b0b-4ba3-9112-80c733998dbe",
   "metadata": {},
   "source": [
    "Provide a brief description of your source material, including its provenance and content. Tell us where you found it and what kind of content it contains.\n",
    "\n",
    "This dataset was found on Kaggle. It includes Reddit posts from 2016-2021 of posts that are related to AAPL stock and Apple. This dataset was created to allow people to perform NLP and sentiment analysis to find potential relationships with Apple and AAPL stock. At the meta level, it includes subreddit information such as its ID, name, NSFW status. At the post level, we have the post content, the number of upvotes, the title of the post, a link to the post, and the time it was created in UTC. \n",
    "\n",
    "\n",
    "As a side note, the data states it is from 2005-2010. However, after checking the posts themselves, they are from 2016-2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b507c1-6dc2-44f7-b74c-790d84a48e8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Features (1)\n",
    "\n",
    "Add values for the following items. (Do this for all following bulleted lists.)\n",
    "\n",
    "- Source URL: https://www.kaggle.com/datasets/thedevastator/aapl-on-reddit-2005-2010/\n",
    "- UVA Box URL: https://virginia.box.com/s/7vz6uz9cp7gtsjxg9yu6gk1clsp9uvp6\n",
    "- Number of raw documents: A CSV with 15483 reddit posts.\n",
    "- Total size of raw documents (e.g. in MB): 7.1 MB \n",
    "- File format(s), e.g. XML, plaintext, etc.: CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e81b1-9f70-47b5-bb25-49be4e76b98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Document Structure (1)\n",
    "\n",
    "Provide a brief description of the internal structure of each document. That, describe the typical elements found in document and their relation to each other. For example, a corpus of letters might be described as having a date, an addressee, a salutation, a set of content paragraphs, and closing. If they are various structures, state that.\n",
    "\n",
    "Each document contains its subreddit ID, a subreddit name, a boolean value for if the subreddit is NSFW, the time it was created, the link to the post, the domain, a link to websites or images the post may include, the text of the post, the title of the post, and the score of the post (the number of upvotes it has)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec4c9f-e101-46fe-ac59-a35a1b148a4b",
   "metadata": {},
   "source": [
    "# Parsed and Annotated Data\n",
    "\n",
    "Parse the raw data into the three core tables of your addition: the `LIB`, `CORPUS`, and `VOCAB` tables.\n",
    "\n",
    "These tables will be stored as CSV files with header rows.\n",
    "\n",
    "You may consider using `|` as a delimitter.\n",
    "\n",
    "Provide the following information for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d05ce4-ac5c-43ea-a07b-c4626338f80e",
   "metadata": {},
   "source": [
    "## LIB (2)\n",
    "\n",
    "The source documents the corpus comprises. These may be books, plays, newspaper articles, abstracts, blog posts, etc. \n",
    "\n",
    "Note that these are *not* documents in the sense used to describe a bag-of-words representation of a text, e.g. chapter.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/8lri1rb37m5z61rckbscdbkje24mwakt\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Number of observations: 12 subreddits with a total of 1065 posts. I limited the library to subreddits with over 10 posts that had 5 or more upvotes and 50 or more characters.\n",
    "- List of features, including at least three that may be used for model summarization (e.g. date, author, etc.): Subreddit name, subreddit description, number of posts, mean/median scores of posts.\n",
    "- Average length of each document in characters: 937.84 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304204a5-00be-46ad-b98b-0d10a9c8ca4b",
   "metadata": {},
   "source": [
    "## CORPUS (2)\n",
    "\n",
    "The sequence of word tokens in the corpus, indexed by their location in the corpus and document structures.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/82kbtne5dcrn3hrkzyv2p2iazswtc8jl\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Number of observations Between (should be >= 500,000 and <= 2,000,000 observations.): 168341. \n",
    "- OHCO Structure (as delimitted column names): 'subreddit_num','post_num','paragraph_num','sentence_num'\n",
    "- Columns (as delimitted column names, including `token_str`, `term_str`, `pos`, and `pos_group`): 'subreddit_num', 'post_num', 'paragraph_num', 'sentence_num', 'token_num', 'token_str', 'term_str', 'pos', 'pos_group'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3214e-e6dd-42d6-842f-555d0058986e",
   "metadata": {},
   "source": [
    "## VOCAB (2)\n",
    "\n",
    "The unique word types (terms) in the corpus.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/t7l5gmwdl8hgxtet6aezconblrc6rrxn\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Number of observations: 10369\n",
    "- Columns (as delimitted names, including `n`, `p`', `i`, `dfidf`, `porter_stem`, `max_pos` and `max_pos_group`, `stop`): 'term_str', 'n', 'p', 'i', 'max_pos', 'max_pos_group', 'stop', 'porter_stem', 'dfidf'\n",
    "- List the top 20 significant words in the corpus by DFIDF; 'one', 'average', 'time', 'an', 'price', 'now', 'in', 'there', 'of', 'up', 'would', 'them', 'not', 'if', 'their', 'the', 'or', 'that', 'other', 'was'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dabdc-baae-4408-95bc-2f735824d59b",
   "metadata": {},
   "source": [
    "# Derived Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2ef9c-1cb5-41e8-a5ee-1e37428b4539",
   "metadata": {},
   "source": [
    "## BOW (3)\n",
    "\n",
    "A bag-of-words representation of the CORPUS.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/8x3vvlwe7ge7irnaki9cvlglki8z1sx5\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Bag (expressed in terms of OHCO levels): 'subreddit_num' or OHCO[:1]\n",
    "- Number of observations: 26413\n",
    "- Columns (as delimitted names, including `n`, `tfidf`): 'subreddit_num', 'term_str','n', 'tfidf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29890d2f-bf96-43ad-8d08-792393830163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DTM (3)\n",
    "\n",
    "A represenation of the BOW as a sparse count matrix.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/tbi48q7r9xic8hnyixaawu768d4k99qn\n",
    "- UVA Box URL of BOW used to generate (if applicable): https://virginia.box.com/s/8x3vvlwe7ge7irnaki9cvlglki8z1sx5\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Bag (expressed in terms of OHCO levels): 'subreddit_num' or OHCO[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b4774-7c76-401d-a9de-2704f28a0821",
   "metadata": {},
   "source": [
    "## TFIDF (3)\n",
    "\n",
    "A Document-Term matrix with TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/ue0a4cab6cigggqtehoakeju9rbnj8vk\n",
    "- UVA Box URL of DTM or BOW used to create: https://virginia.box.com/s/8x3vvlwe7ge7irnaki9cvlglki8z1sx5\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Description of TFIDIF formula ($\\LaTeX$ OK): I used 'subbredit_num' as the bag of words and then used the sum term factor method. This calculates TF the sum of the term's occurrences in a document, and IDF is the logarithm of the total number of documents divided by the document frequency of the term. Multiplying these two together, you get TFIDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34f5ca-5361-4701-b9dd-9da66859b40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced and Normalized TFIDF_L2 (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c548dd2-f692-4365-936c-39c84df79b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "A Document-Term matrix with L2 normalized TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/iochznoljujb90cmby1kps5k5xrdopl3\n",
    "- UVA Box URL of source TFIDF table: https://virginia.box.com/s/ue0a4cab6cigggqtehoakeju9rbnj8vk\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Number of features (i.e. significant words): 3791\n",
    "- Principle of significant word selection: I chose words that had a DFIDF value over the mean DFIDF value of across the entire vocabulary which was 4.70. I also subset words that are adjectives, verbs, and nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50da94-af36-4e8d-b1a7-24dbcf431880",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df79264-dd93-4199-be38-db31579b7ce8",
   "metadata": {},
   "source": [
    "## PCA Components (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/brfpyvxvut18yw32p4k5c1n365wkse98\n",
    "- UVA Box URL of the source TFIDF_L2 table: https://virginia.box.com/s/iochznoljujb90cmby1kps5k5xrdopl3\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Number of components: 5 \n",
    "- Library used to generate: Code from module 7.01 \n",
    "- Top 5 positive terms for first component: 'ampnbsp', 'spreadsheet', 'iv', 'calls', 'call'\n",
    "- Top 5 negative terms for second component: 'iphone', 'amp', 'calls', 'sales', 'saw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adc882-cbce-4d24-9923-5d36ac609f43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA DCM (4)\n",
    "\n",
    "The document-component matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/kcc27zee9xignyni7d2zkygp4s49h8ev\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd2a4a-7f2f-4259-a5c4-063168cb1b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA Loadings (4)\n",
    "\n",
    "The component-term matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/dty4x1t184ju0o6d2k3qkkheq2pbmx2r\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fff42f-6665-4941-ba3d-034627dc0124",
   "metadata": {},
   "source": [
    "## PCA Visualization 1 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the first two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![](plots/pca_1.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the first component:\n",
    "\n",
    "The metadata feature chosen is the mean average number of upvotes in each subreddit. The plot on the left shows that subreddits with higher upvote averages tend to have content that is negative in both principle component 0 and 1. These principle components relate to iphones, China, calls, dividends, and sales, indicating a general notion of sales revenue and AAPL option/stock. The plot on the right shows the contribution of each word to the principal components, which seem to cluster around 0.0 on PC0 and vary much more on PC1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb54565-7669-4a2f-90b2-a4c283277c02",
   "metadata": {},
   "source": [
    "## PCA Visualization 2 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the second two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![](plots/pca_2.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the second component:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75facc37",
   "metadata": {},
   "source": [
    "The metadata feature chosen is the mean average number of upvotes in each subreddit. The plot on the left shows that subreddits with higher upvote averages tend to have content that is neutral or centered around 0 in both both principle component 2 and 3. These principle components relate to forecasts, alerts, dividends, payouts, and packages, indicating a general notion of forecasted/guaranteed profits. The plot on the right shows the contribution of each word to the principal components, which seem to cluster around 0.0 on both components, with some trails of outliers going in a few directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee23b2-25d1-4226-bf31-1607e5ed4677",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA TOPIC (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/d87kexl0nwczdgrqyvq3p3lt2hgpycrh\n",
    "- UVA Box URL of count matrix used to create: https://virginia.box.com/s/tbi48q7r9xic8hnyixaawu768d4k99qn\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Libary used to compute: LatentDirichletAllocation from sklearn\n",
    "- A description of any filtering, e.g. POS (Nouns and Verbs only): Nouns\n",
    "- Number of components: 5\n",
    "- Any other parameters used: bag = subreddit_num or OHCO[:1], ngram_range = (1, 2), n_top_terms = 5, max_features = 1000, stop_words = 'english', max_iter = 5, learning_offset = 50, random_state = 0 ngram_range\n",
    "- Top 5 words and best-guess labels for topic five topics by mean document weight:\n",
    "  - T01: apple stock market year company, Company Performance\n",
    "  - T02: apple earnings options week stock, Earnings and Options\n",
    "  - T00: apple iphone market earnings stock, iPhone Market Impact\n",
    "  - T04: apple stock calls im earnings, Stock and Earnings Calls\n",
    "  - T03: table perfect averages reversal setup, Financial Market Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518d520-4a5c-48fa-836d-f8ea3e3c2f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA THETA (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/3u0qpd0gaewy8n8ycvubrgarq64eayt9\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8808b30-64f4-4249-95d5-d7c0925ce432",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA PHI (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/muo2d6xzps4fyjqn2qaqpk6uq3vz6135\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e404bf-8a2a-4eb4-ba89-0c708c8f359d",
   "metadata": {},
   "source": [
    "## LDA + PCA Visualization (4)\n",
    "\n",
    "Apply PCA to the PHI table and plot the topics in the space opened by the first two components.\n",
    "\n",
    "Size the points based on the mean document weight of each topic (using the THETA table).\n",
    "\n",
    "Color the points basd on a metadata feature from the LIB table.\n",
    "\n",
    "Provide a brief interpretation of what you see.\n",
    "\n",
    "![](plots/lda_pca.png)\n",
    "\n",
    "This plot of PCA of LDA shows that PC0 does well to capture the variation in the topics while PC1 mainly splits T01 (Company Performance, bottom left) from the other 4 topics. PC1 also shows the similarities between T02 (Earnings and Options top right), T00 (iPhone Market Impact, top left),  T04 (Stock and Earnings Calls, top middle), which is to be expected. There is a small point representing T03 at PC0=0 and PC1=0 that is small and hard to see, representing its low topic weight and importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1f327-a386-476a-8d94-2ab7a63afa7a",
   "metadata": {},
   "source": [
    "## Sentiment VOCAB_SENT (4)\n",
    "\n",
    "Sentiment values associated with a subset of the VOCAB from a curated sentiment lexicon.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/grlqn5plxbderi7zru619vk24huyktef\n",
    "- UVA Box URL for source lexicon: https://virginia.box.com/s/kgk3b0q07tmcvz94zmawfb4jh843nnpa\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a9d67-1560-4be9-b82a-b99a60b5c93e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment BOW_SENT (4)\n",
    "\n",
    "Sentiment values from VOCAB_SENT mapped onto BOW.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/bw9u0jf3m7lb4mb4v4islpvtulpshxdq\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee6837-b12e-453d-96c1-59eaa4b28883",
   "metadata": {},
   "source": [
    "## Sentiment DOC_SENT (4)\n",
    "\n",
    "Computed sentiment per bag computed from BOW_SENT.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/j574cusogcznda82rcsjowk023bd98vo\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Document bag expressed in terms of OHCO levels: subreddit_num or OHCO[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cba13-e60a-4940-a06d-02479f002c3c",
   "metadata": {},
   "source": [
    "## Sentiment Plot (4)\n",
    "\n",
    "Plot sentiment over some metric space, such as time.\n",
    "\n",
    "If you don't have a metric metadata features, plot sentiment over a feature of your choice.\n",
    "\n",
    "You may use a bar chart or a line graph.\n",
    "\n",
    "![](plots/sentiment_subreddit.png)\n",
    "\n",
    "The plot on the right shows initial sentiment scores for each subreddit. However, subreddits at the top have significantly less posts than those at the bottom, which may lead to skewed results as there could be a few posts with more extreme sentiment, so I scaled the emotion values by the number of posts as shown on the right. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d2316-317b-4d95-a804-aff98242e411",
   "metadata": {},
   "source": [
    "## VOCAB_W2V (4)\n",
    "\n",
    "A table of word2vec features associated with terms in the VOCAB table.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/dc0hks6esd7wsbns89bs24a60a80llli\n",
    "- GitHub URL for notebook used to create: https://github.com/kristianolsson23/DS5001_AAPL_Reddit_Analysis/blob/main/FinalProject_Code.ipynb\n",
    "- Delimitter: ,\n",
    "- Document bag expressed in terms of OHCO levels: subreddit_num or OHCO[:1]\n",
    "- Number of features generated: 246 \n",
    "- The library used to generate the embeddings: gensim.models word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c1974-047b-4285-9f4d-7f3314f39542",
   "metadata": {},
   "source": [
    "## Word2vec tSNE Plot (4)\n",
    "\n",
    "Plot word embedding featues in two-dimensions using t-SNE.\n",
    "\n",
    "Describe a cluster in the plot that captures your attention.\n",
    "\n",
    "![](plots/tsne.png)\n",
    "\n",
    "![](plots/tsne_subset.png)\n",
    "\n",
    "\n",
    "I found a cluster between x=(19,25), y=(-7,-5) that captured my attention. There are many financial terms such as eps (earnings per share), revenue, and expected, potentially referring to expected revenue. There are also terms relating to periods in finance such as quarter and year. Lastly, terms that relate to the performance of the company such as services, sales, growth, and most importantly, the iPhone. These represent many of the main forces in considering the performance of Apple and AAPL stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75878341-7fe8-4e22-b908-36029f9818e8",
   "metadata": {},
   "source": [
    "# Riffs\n",
    "\n",
    "Provde at least three visualizations that combine the preceding model data in interesting ways.\n",
    "\n",
    "These should provide insight into how features in the LIB table are related. \n",
    "\n",
    "The nature of this relationship is left open to you -- it may be correlation, or mutual information, or something less well defined. \n",
    "\n",
    "In doing so, consider the following visualization types:\n",
    "\n",
    "- Hierarchical cluster diagrams\n",
    "- Heatmaps\n",
    "- Scatter plots\n",
    "- KDE plots\n",
    "- Dispersion plots\n",
    "- t-SNE plots\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62acf1-6bb0-45d0-aed2-863b285f8cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 1 (5)\n",
    "\n",
    "![](plots/hierarchical_subreddit.png)\n",
    "\n",
    "Using a hierarchical cluster with a cosine similarity score, we are able to see the similarities between specific subreddits. The top purple cluster represents stock trading, dividends, and Apple stock specifically. The red cluster represents options as all three subreddits are described as option focused (where theta measures the rate of time decay of an option's premium). The green cluster, similar to the purple cluster, represents stock trading but with a more general focus on investing and the market. The orange cluster represents a couple of subreddits with a general interest in investing with no specific focus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155a072-02b3-4aa8-b9f1-e43a59e9a85d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 2 (5)\n",
    "\n",
    "![](plots/sentiment_time.png)\n",
    "\n",
    "![](plots/apple_stock.png)\n",
    "\n",
    "This plot represents emotions and sentiment over time. From the end of 2016 to mid 2018, we see some signal across the emotions, with a high spike mid 2018 although this is mainly due to a lack of posts in that month. The emotions are calmer between mid 2018 and mid 2019, before becoming quite noisy again in mid 2019. From 2020 onwards, it is relatively calm. I also attached a plot of AAPL's performance across the same period. We can see a steady increase in price over time, with a large growth from COVID onwards. There are a couple of drops in price in late 2018 and the early 2020, which do not correlate exactly to the sentiments. However, it feels like there is a time lag from the sentiments to the market, as there are big drops and changes in sentiment and emotions a couple of months before these drops in prices. This may indicate there is some correlaton between public opinion and stock price, although it is not a significant relationship based on these plots.\n",
    "\n",
    "In terms of specific emotions, it is worth noting trust and anticipation are very highly correlated while sentiment seems to have an inverse relationship with these two. It may indicate that while people's sentiment is low, there is a lot of hope that it will improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067c59b-8983-4acc-972a-1ecd852ded57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 3 (5)\n",
    "\n",
    "![](plots/hierarchical_word.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c120b",
   "metadata": {},
   "source": [
    "Using a hierarchical cluster on Word2Vec inputs, we are able to find relationships between specific words and groups of words. I sampled 75 words that are nouns and have a DFIDF value greater than the mean DFIDF value. There are two main clusters, with just 4 words in the orange cluster representing an array of topics such as iPhones, billion, and earnings. Within the subclusters in the larger green cluster, there are groups of words that closely relate such as thoughts, hope, strategy, thanks, thinking, loss, feel all relating to emotion and coming up with a strategy. We also see a more consumer focused cluster with 2020, consumer, iPhone, results, store, home, expectations, and increasing near the top. This cluster diagram provides a great way to visually group words and find some closely related words within this corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e25c6e-2624-4899-829e-e7d60c878685",
   "metadata": {},
   "source": [
    "# Interpretation (4)\n",
    "\n",
    "Describe something interesting about your corpus that you discovered during the process of completing this assignment.\n",
    "\n",
    "At a minumum, use 250 words, but you may use more. You may also add images if you'd like.\n",
    "\n",
    "(INSERT INTERPRETATION HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edf6ce",
   "metadata": {},
   "source": [
    "To be honest, I was unsure but excited about what relationships and patterns I would be able to find with this dataset, especially considering how small it is.  However, I was blown away by some of the insights I came upon. A few that I find to be very interesting are:\n",
    "\n",
    "- A large change in sentiment over time could be an indicator of decreases to stock price, while a less emotional and calmer sentiment may indicate increases in stock price, as shown in the sentiment plot across time. \n",
    "\n",
    "- Every subreddit related to options has a negative sentiment, likely due to the higher risk/reward the asset provides, as shown in the sentiment plot across subreddits. On the other hand, subreddits related to day trading and stock trading had heightened levels of fear, which makes sense as you may be constantly watching and reacting to price changes.\n",
    "\n",
    "- Clustering is a reliable method to find relationships between different values, whether that be in clustering words that relate to consumers or finding subreddits specific to stock versus options trading.\n",
    "\n",
    "- t-SNE plots are effective in reducing the dimensionality of words and creating groups of closely related terms, such as words that indicate the performance of Apple.\n",
    "\n",
    "This type of quantitative analysis into public opinion can provide many insights into what investors are researching and considering, what sentiments they might have based on what community (subreddit) they are a part of or when they post, and changes to stock price that may occur as a result. Overall, this project and this course was very mind-opening into understanding language from a qualitative and quantitative perspective.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
